---
layout: single
title: "æ·±åº¦å­¦ä¹ å®æˆ˜ï¼šä½¿ç”¨PyTorchæ„å»ºå·ç§¯ç¥ç»ç½‘ç»œ"
date: 2025-01-20
categories: [æ·±åº¦å­¦ä¹ , Python, PyTorch]
tags: [CNN, å›¾åƒåˆ†ç±», æ·±åº¦å­¦ä¹ , PyTorch]
excerpt: "æœ¬æ•™ç¨‹å°†å¸¦æ‚¨ä½¿ç”¨PyTorchæ„å»ºä¸€ä¸ªå®Œæ•´çš„å·ç§¯ç¥ç»ç½‘ç»œ(CNN)æ¥è§£å†³å›¾åƒåˆ†ç±»é—®é¢˜ã€‚æˆ‘ä»¬å°†ä½¿ç”¨CIFAR-10æ•°æ®é›†æ¥è®­ç»ƒæ¨¡å‹è¯†åˆ«10ç§ä¸åŒçš„ç‰©ä½“ç±»åˆ«ã€‚"
---

# æ·±åº¦å­¦ä¹ å®æˆ˜ï¼šä½¿ç”¨PyTorchæ„å»ºå·ç§¯ç¥ç»ç½‘ç»œ

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

æœ¬æ•™ç¨‹å°†å¸¦æ‚¨ä½¿ç”¨PyTorchæ„å»ºä¸€ä¸ªå®Œæ•´çš„å·ç§¯ç¥ç»ç½‘ç»œ(CNN)æ¥è§£å†³å›¾åƒåˆ†ç±»é—®é¢˜ã€‚æˆ‘ä»¬å°†ä½¿ç”¨CIFAR-10æ•°æ®é›†æ¥è®­ç»ƒæ¨¡å‹è¯†åˆ«10ç§ä¸åŒçš„ç‰©ä½“ç±»åˆ«ã€‚

## ğŸ“Š æ•°æ®é›†ä»‹ç»

![CIFAR-10æ•°æ®é›†ç¤ºä¾‹]({{ site.baseurl }}/assets/images/posts/cifar10-dataset.jpg)

CIFAR-10æ•°æ®é›†åŒ…å«60,000å¼ 32x32åƒç´ çš„å½©è‰²å›¾åƒï¼Œåˆ†ä¸º10ä¸ªç±»åˆ«ï¼š
- é£æœº (airplane)
- æ±½è½¦ (automobile) 
- é¸Ÿç±» (bird)
- çŒ« (cat)
- é¹¿ (deer)
- ç‹— (dog)
- é’è›™ (frog)
- é©¬ (horse)
- èˆ¹ (ship)
- å¡è½¦ (truck)

## ğŸ—ï¸ ç½‘ç»œæ¶æ„

![CNNç½‘ç»œæ¶æ„å›¾]({{ site.baseurl }}/assets/images/posts/cnn-architecture.jpg)

æˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªåŒ…å«ä»¥ä¸‹å±‚çš„CNNï¼š
- å·ç§¯å±‚ (Convolutional Layers)
- æ‰¹å½’ä¸€åŒ– (Batch Normalization)
- æ¿€æ´»å‡½æ•° (ReLU)
- æ± åŒ–å±‚ (Max Pooling)
- å…¨è¿æ¥å±‚ (Fully Connected Layers)
- Dropout (é˜²æ­¢è¿‡æ‹Ÿåˆ)

## ğŸ’» å®Œæ•´ä»£ç å®ç°

### å¯¼å…¥å¿…è¦çš„åº“

```python
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
from torch.utils.data import DataLoader
```

### æ•°æ®é¢„å¤„ç†

```python
# å®šä¹‰æ•°æ®å˜æ¢
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

# åŠ è½½è®­ç»ƒé›†å’Œæµ‹è¯•é›†
trainset = torchvision.datasets.CIFAR10(
    root='./data', train=True, download=True, transform=transform
)
trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(
    root='./data', train=False, download=True, transform=transform
)
testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)

# ç±»åˆ«åç§°
classes = ('plane', 'car', 'bird', 'cat', 'deer',
           'dog', 'frog', 'horse', 'ship', 'truck')
```

### å®šä¹‰CNNæ¨¡å‹

```python
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        
        # ç¬¬ä¸€ä¸ªå·ç§¯å—
        self.conv1 = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        
        # ç¬¬äºŒä¸ªå·ç§¯å—
        self.conv2 = nn.Sequential(
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        
        # ç¬¬ä¸‰ä¸ªå·ç§¯å—
        self.conv3 = nn.Sequential(
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        
        # å…¨è¿æ¥å±‚
        self.fc = nn.Sequential(
            nn.Linear(128 * 4 * 4, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(512, 10)
        )
        
    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = x.view(x.size(0), -1)  # å±•å¹³
        x = self.fc(x)
        return x

# åˆ›å»ºæ¨¡å‹å®ä¾‹
model = CNN()
print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
```

### è®­ç»ƒå‡½æ•°

```python
def train_model(model, trainloader, epochs=50, learning_rate=0.001):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    model.to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    
    train_losses = []
    train_accs = []
    
    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0
        
        for i, data in enumerate(trainloader, 0):
            inputs, labels = data[0].to(device), data[1].to(device)
            
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            
            if i % 200 == 199:
                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 200:.3f}')
                running_loss = 0.0
        
        # è®¡ç®—è®­ç»ƒå‡†ç¡®ç‡
        train_acc = 100 * correct / total
        train_accs.append(train_acc)
        train_losses.append(running_loss / len(trainloader))
        
        print(f'Epoch {epoch + 1} - è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.2f}%')
    
    return train_losses, train_accs

# å¼€å§‹è®­ç»ƒ
print("å¼€å§‹è®­ç»ƒæ¨¡å‹...")
train_losses, train_accs = train_model(model, trainloader, epochs=20)
```

### æµ‹è¯•å‡½æ•°

```python
def test_model(model, testloader):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    model.eval()
    
    correct = 0
    total = 0
    class_correct = list(0. for i in range(10))
    class_total = list(0. for i in range(10))
    
    with torch.no_grad():
        for data in testloader:
            images, labels = data[0].to(device), data[1].to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            
            # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡
            c = (predicted == labels).squeeze()
            for i in range(labels.size(0)):
                label = labels[i]
                class_correct[label] += c[i].item()
                class_total[label] += 1
    
    print(f'æ•´ä½“æµ‹è¯•å‡†ç¡®ç‡: {100 * correct / total:.2f}%')
    
    # æ‰“å°æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡
    for i in range(10):
        print(f'{classes[i]}: {100 * class_correct[i] / class_total[i]:.2f}%')

# æµ‹è¯•æ¨¡å‹
print("\nå¼€å§‹æµ‹è¯•æ¨¡å‹...")
test_model(model, testloader)
```

### å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹

```python
def plot_training_results(train_losses, train_accs):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # ç»˜åˆ¶æŸå¤±æ›²çº¿
    ax1.plot(train_losses)
    ax1.set_title('è®­ç»ƒæŸå¤±')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.grid(True)
    
    # ç»˜åˆ¶å‡†ç¡®ç‡æ›²çº¿
    ax2.plot(train_accs)
    ax2.set_title('è®­ç»ƒå‡†ç¡®ç‡')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy (%)')
    ax2.grid(True)
    
    plt.tight_layout()
    plt.show()

# ç»˜åˆ¶è®­ç»ƒç»“æœ
plot_training_results(train_losses, train_accs)
```

#### è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–ç¤ºä¾‹

![è®­ç»ƒæŸå¤±æ›²çº¿]({{ site.baseurl }}/assets/images/posts/training-loss-curve.jpg)

![æ¨¡å‹æ€§èƒ½å›¾è¡¨]({{ site.baseurl }}/assets/images/posts/model-performance-chart.jpg)

### ä¿å­˜æ¨¡å‹

```python
# ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹
torch.save(model.state_dict(), 'cifar10_cnn.pth')
print("æ¨¡å‹å·²ä¿å­˜ä¸º 'cifar10_cnn.pth'")

# åŠ è½½æ¨¡å‹ç¤ºä¾‹
def load_model():
    model = CNN()
    model.load_state_dict(torch.load('cifar10_cnn.pth'))
    return model

# ä½¿ç”¨åŠ è½½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹
def predict_image(model, image_path):
    from PIL import Image
    import torchvision.transforms as transforms
    
    # å›¾åƒé¢„å¤„ç†
    transform = transforms.Compose([
        transforms.Resize((32, 32)),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0)
    
    # é¢„æµ‹
    model.eval()
    with torch.no_grad():
        output = model(image)
        _, predicted = torch.max(output, 1)
        
    return classes[predicted.item()]

# ç¤ºä¾‹ï¼šé¢„æµ‹å•å¼ å›¾åƒ
# result = predict_image(model, 'path_to_your_image.jpg')
# print(f'é¢„æµ‹ç»“æœ: {result}')
```

## ğŸ“ˆ æ€§èƒ½åˆ†æ

### è®­ç»ƒç»“æœ
- **è®­ç»ƒè½®æ•°**: 20 epochs
- **æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡**: çº¦85-90%
- **æµ‹è¯•å‡†ç¡®ç‡**: çº¦80-85%
- **è®­ç»ƒæ—¶é—´**: çº¦30-60åˆ†é’Ÿï¼ˆå–å†³äºç¡¬ä»¶ï¼‰

### æ¨¡å‹ç‰¹ç‚¹
- **å‚æ•°æ•°é‡**: çº¦1.2M
- **ç½‘ç»œæ·±åº¦**: 3ä¸ªå·ç§¯å— + 2ä¸ªå…¨è¿æ¥å±‚
- **æ­£åˆ™åŒ–**: BatchNorm + Dropout
- **ä¼˜åŒ–å™¨**: Adam

## ğŸ”§ æ”¹è¿›å»ºè®®

1. **æ•°æ®å¢å¼º**: æ·»åŠ æ›´å¤šæ•°æ®å˜æ¢æé«˜æ³›åŒ–èƒ½åŠ›
2. **å­¦ä¹ ç‡è°ƒåº¦**: ä½¿ç”¨å­¦ä¹ ç‡è¡°å‡ç­–ç•¥
3. **æ—©åœæœºåˆ¶**: é˜²æ­¢è¿‡æ‹Ÿåˆ
4. **æ¨¡å‹é›†æˆ**: ç»“åˆå¤šä¸ªæ¨¡å‹æé«˜æ€§èƒ½
5. **è¶…å‚æ•°è°ƒä¼˜**: ä½¿ç”¨ç½‘æ ¼æœç´¢æˆ–è´å¶æ–¯ä¼˜åŒ–

## ğŸ“š æ‰©å±•é˜…è¯»

- [PyTorchå®˜æ–¹æ•™ç¨‹](https://pytorch.org/tutorials/)
- [æ·±åº¦å­¦ä¹ èŠ±ä¹¦](https://www.deeplearningbook.org/)
- [CIFAR-10æ•°æ®é›†è®ºæ–‡](https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf)

## ğŸ‰ æ€»ç»“

æœ¬æ•™ç¨‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨PyTorchæ„å»ºä¸€ä¸ªå®Œæ•´çš„CNNæ¨¡å‹ã€‚é€šè¿‡è¿™ä¸ªé¡¹ç›®ï¼Œæ‚¨å­¦ä¼šäº†ï¼š

1. æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
2. æ¨¡å‹æ¶æ„è®¾è®¡
3. è®­ç»ƒå’Œæµ‹è¯•æµç¨‹
4. æ¨¡å‹ä¿å­˜å’ŒåŠ è½½
5. ç»“æœå¯è§†åŒ–

è¿™ä¸ªé¡¹ç›®ä¸ºæ·±åº¦å­¦ä¹ å…¥é—¨æä¾›äº†å¾ˆå¥½çš„å®è·µåŸºç¡€ï¼Œæ‚¨å¯ä»¥åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œæ›´å¤šæ¢ç´¢å’Œæ”¹è¿›ï¼

---

*æœ€åæ›´æ–°æ—¶é—´: 2025å¹´1æœˆ20æ—¥* 